\documentclass[12pt]{article}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\linespread{1}
\pagestyle{empty}
\setlength\parindent{12pt}


\usepackage[top=1in,bottom=1in,left=1in,right=1in]{geometry}
\title{6.852 Distributed Algorithms Project Proposal}
\author{Ariel Anders and Noel Hollingsworth}

\begin{document}
\begin{center}{\bf \Large
6.852 Distributed Algorithms Project Proposal\\ }
Ariel Anders and Noel Hollingsworth 
\end{center}
We propose to do a reading project of distributed reinforcement learning. Our project motivation comes from the problem of determining the behavior of modular robotics, such as in \cite{modrobots}. These modular robots can take the form of many different configurations to accomplish a goal, such as moving to a specific location.   Based on the initial configuration, a unique policy may be required to result in a goal configuration. Hard coding such a policy  can be impractical, as there are many different possible configurations. Reinforcement learning is a way to learn the appopriate behavior through experience, rather than through human knowledge. We believe that this particular project is not in an advanced enough state to consider doing an experimental project involving reinforcement learning given the scope of the final project, and that a reading project could serve as a good introduction for later experimental work with these robots.\par

Reinforcement learning is the study of how agents in an environment should take actions to maximize their reward \cite{reinforcement}. For the modular robotics domain a simple problem would be how much force the individual robot should apply to its motor, given its place in a configuration and a desired final location. The entire configuration would be assigned a large reward when it arrived at its desired location quickly, and a small reward when it took a long time to arrive at the desired location. Reinforcement learning in a distributed setting is a more challenging problem than traditional reinforcement learning, as agents role in the overall system may change, and it's often unclear how much each agent contributes or detracts from the overall effectiveness of the system.\par

\cite{distributedreinforcement} and \cite{scalablelocomotion} will serve as the starting point for our survey of distributed reinforcement learning. We intend to focus on papers that deal with problems at the intersection of distributed algorithms and reinforcement learning, such as what to communicate to other robots in a configuration when the configuration changes. We hope that the papers we describe can be applied to modular robotics, ideally to similar problems as \cite{modrobots} is dealing with, so that our work can act as a background for future empirical work. 
\begin{thebibliography}{9}
\bibitem{modrobots}
http://web.mit.edu/newsoffice/2013/simple-scheme-for-self-assembling-robots-1004.html
\bibitem{reinforcement}
L. P. Kaelbling, L. M. Littman, and A. W. Moore, “Reinforcement
learning: A survey,” J. Artif. Intell. Res., vol. 4, pp. 237–285, 1996.
\bibitem{distributedreinforcement}
Paulina Varshavskaya, Leslie Pack Kaelbling, and Daniela Rus, "Efficient Distributed Reinforcement Learning Through Agreement," 9th International Symposium on Distributed Autonomous Robotic Systems (DARS), Tsukuba Japan, November 2008.
\bibitem{scalablelocomotion}
Robert Fitch and  Zack Butler, ``Scalable locomotion for large self-reconfiguring robots,"Robotics and Automation, 2007 IEEE International Conference on Robotics and Automation, Roma, Italy, 10-14 April 2007.

\end{thebibliography}
\end{document}